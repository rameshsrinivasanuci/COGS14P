{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 4 Histograms and Visualizing Summary Statistics\n",
    "\n",
    "## In this tutorial we will learn how to work with data to visualize data distributions and summary statistics.\n",
    "\n",
    "### For the demonstrations here we will make use of the response time data from my lab experiment we looked at in class.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rtdata = pd.read_excel('rtdata.xlsx')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Before we get started, lets copy the values from the DataFrame to variables \n",
    "### I always go ahead and convert them into numpy arrays "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trialnumber = np.array(rtdata['trialnumber'])\n",
    "condition = np.array(rtdata['condition'])\n",
    "responsetime = np.array(rtdata['responsetime'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1  TASK: Compute the mean, median, 25th percentile, and 75th percentile of response time for each condition.  \n",
    "\n",
    "### HINT: USE LOGICAL STATEMENTS TO CREATE BOOLEAN VARIABLES THAT IDENTIFY THE TRIALS CORRESPONDING TO EACH CONDITION.   \n",
    "\n",
    "### First let's separate the data into 3 different variables corresponding to each condition in the experiment.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rt1 = responsetime[condition ==1] # data for condition 1\n",
    "rt2 = responsetime[condition ==2] # data for condition 2\n",
    "rt3 = responsetime[condition ==3] # data for condition 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### I am going to make variables that will hold the summary statistics.  Since I know there are EXACTLY 3 conditions, I will make arrays of size 3 to save these variables. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean_rt = np.zeros(3) \n",
    "median_rt = np.zeros(3)\n",
    "pc25_rt = np.zeros(3)\n",
    "pc75_rt = np.zeros(3)\n",
    "std_rt = np.zeros(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lets fill each of these for condition.  In each case the output is an array with 3 values, 1 for each condition.   "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# means\n",
    "mean_rt[0] = np.mean(rt1) \n",
    "mean_rt[1] = np.mean(rt2)\n",
    "mean_rt[2] = np.mean(rt3)\n",
    "print(mean_rt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# median \n",
    "median_rt[0] = np.median(rt1) \n",
    "median_rt[1] = np.median(rt2)\n",
    "median_rt[2] = np.median(rt3)\n",
    "print(median_rt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 25th percentile\n",
    "pc25_rt[0] = np.percentile(rt1,25) \n",
    "pc25_rt[1] = np.percentile(rt2,25)\n",
    "pc25_rt[2] = np.percentile(rt3,25)\n",
    "print(pc25_rt)\n",
    "# 75th percentile \n",
    "pc75_rt[0] = np.percentile(rt1,75) \n",
    "pc75_rt[1] = np.percentile(rt2,75)\n",
    "pc75_rt[2] = np.percentile(rt3,75)\n",
    "print(pc75_rt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# standard deviation\n",
    "std_rt[0] = np.std(rt1) \n",
    "std_rt[1] = np.std(rt2)\n",
    "std_rt[2] = np.std(rt3)\n",
    "print(std_rt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 Histograms: Visualizing the distribution of the data\n",
    "\n",
    "### One of the basic tools in understanding data is to visualize the **distribution** of the data.  How frequently to different values of the data appear? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### To understand the distribution of the data, the first thing I need to do is to find the minimum and maximum of the data "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "max_rt = np.zeros(3)\n",
    "min_rt = np.zeros(3)\n",
    "max_rt[0] = np.amax(rt1)\n",
    "max_rt[1] = np.amax(rt2)\n",
    "max_rt[2] = np.amax(rt3)\n",
    "min_rt[0] = np.amin(rt1)\n",
    "min_rt[1] = np.amin(rt2)\n",
    "min_rt[2] = np.amin(rt3)\n",
    "print('minimum values:',min_rt)\n",
    "print('maximum values:',max_rt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Condition 1 and Condition 2 have similar data ranges. Condition 3 has a wider range. \n",
    "### For visualization we want to choose a range that encapsulates all the data.  \n",
    "### I am going to choose a range of 0.5 to 1.8 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2.1 A histogram\n",
    "\n",
    "### A **histogram** is a way of visualizing the data by ** counting ** the number of instances of the data at different values. \n",
    "### Of course each value of continuous valued data is (usually) only observed once, so we need to define values carefully. \n",
    "### The data lies in an interval from a minimum to a maximum value.  We can divide the interval into **bins** of the same width. \n",
    "### For example we can make a bin or response time ranging from 1.0 to 1.1, and count the number of times we observe a value \n",
    "### that falls within that interval.  If we do that for every interval of the same size from the minimum to the maximum of the data, we can make \n",
    "### a **histogram**.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize = (4,3)) # I selected the figure dimension here \n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "bins = np.arange(0.5,1.9,0.1) # I specified that i wanted to divide the range from 0.5 to 1.9 in steps of 0.1 \n",
    "ax.hist(rt1,bins) # I made a histogram plot of rt1.  \n",
    "ax.set_xticks(bins)\n",
    "ax.set_xlabel('Response Time (sec)')\n",
    "ax.set_ylabel('Number of Trials')  # the y axis is a count of the number of times (in this case trials) a value is observed in each bin\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### I can use subplots to plot all 3 conditions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig,ax = plt.subplots(1,3,figsize = (12,3)) # I selected the figure dimension here \n",
    "bins = np.arange(0.5,1.9,0.1) # I specified that i wanted to divide the range from 0.5 to 1.9 in steps of 0.1 \n",
    "ax[0].hist(rt1,bins) # I made a histogram plot of rt1.  \n",
    "ax[0].set_xticks(bins)\n",
    "ax[0].set_xlabel('Response Time (sec)')\n",
    "ax[0].set_ylabel('Number of Trials')  # the y axis is a count of the number of times (in this case trials) a value is observed in each bin\n",
    "ax[0].set_title('Condition 1')\n",
    "ax[1].hist(rt2,bins) # I made a histogram plot of rt2.  \n",
    "ax[1].set_xticks(bins)\n",
    "ax[1].set_xlabel('Response Time (sec)')\n",
    "ax[1].set_ylabel('Number of Trials')  # the y axis is a count of the number of times (in this case trials) a value is observed in each bin\n",
    "ax[1].set_title('Condition 2')\n",
    "ax[2].hist(rt3,bins) # I made a histogram plot of rt3.  \n",
    "ax[2].set_xticks(bins)\n",
    "ax[2].set_xlabel('Response Time (sec)')\n",
    "ax[2].set_ylabel('Number of Trials')  # the y axis is a count of the number of times (in this case trials) a value is observed in each bin\n",
    "ax[2].set_title('Condition 3')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### THIS IS NOT A GOOD PLOT! \n",
    "### Why? \n",
    "* ### The y axis is different on each graph making it difficult to compare the graphs.  \n",
    "* ### It would be nice to be able to directly compare the 3 conditions in 1 graph.  \n",
    "### Its really easy to put them all in 1 graph"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bins = np.arange(0.5,1.9,0.1)\n",
    "all_rts = [rt1,rt2,rt3]  # I just made a list with all the rt values. \n",
    "fig = plt.figure(figsize = (4,3))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "ax.hist(all_rts,bins)  #I sent the list containing all 3 arrays. \n",
    "ax.set_xlabel('Response Time (sec)')\n",
    "ax.set_ylabel('Number of Trials')\n",
    "ax.legend(labels = ('Condition 1','Condition 2', 'Condition 3')) #notice in the legend command, i can put the labels here.  \n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Notice there are several key features of the data now visible.  At the smaller values of response time (0.8 or less) we see mostly blue bars (condition 1) while for the large values of response time (1.4 or more) we see mostly green bars (condition 3)\n",
    "### A progressive shift of the distribution to the right (higher values of response time) is clearly visible. \n",
    "\n",
    "### Here i take some aesthetic control of the graph"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize = (4,3))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "bins = np.arange(0.5,1.9,0.1)\n",
    "ax.hist(all_rts,bins,color=('blue','red','black')) # I chose my colors.  \n",
    "ax.set_xlabel('Response Time (sec)')\n",
    "ax.set_ylabel('Number of Trials')\n",
    "ax.legend(labels = ('Condition 1','Condition 2', 'Condition 3'))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 The modern alternative to the histogram - the violin plot  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.violinplot(all_rts)  #this is the call to violin plot \n",
    "ax.set_xticks([1,2,3]) #I limited it to two ticks on the x axis \n",
    "ax.set_xticklabels(['Condition 1','Condition 2','Condition 3']) #I manually selected the x tick labels \n",
    "ax.set_xlabel('Conditions')\n",
    "ax.set_ylabel('Response Time (sec)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The violin plots show the distribution as a \"blob\" where we can see where the values are distributed by how wide the blob is at any point. \n",
    "### It has the advanatage over the histogram that you dont artificially bin the data, and you can get a better overall feel for the distribution. \n",
    "\n",
    "###  It can be useful to add the median, 25th and 75th percentile to a violin plot. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.violinplot(all_rts)  #this is the call to violin plot \n",
    "ax.plot([1,2,3],median_rt,'gD',markersize = 12)\n",
    "ax.plot([1,2,3],pc25_rt,'ro')\n",
    "ax.plot([1,2,3],pc75_rt,'ro')\n",
    "ax.set_xticks([1,2,3]) #I limited it to two ticks on the x axis \n",
    "ax.set_xticklabels(['Condition 1','Condition 2','Condition 3']) #I manually selected the x tick labels \n",
    "ax.set_xlabel('Conditions')\n",
    "ax.set_ylabel('Response Time (sec)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4. Plotting summary statistics - errorbar\n",
    "\n",
    "### We can also represent the distribution of the data using the mean and standard deviation "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar([1,2,3],mean_rt,color = 'blue', yerr = std_rt,capsize = 5) #this is the same bar command as before, BUT I added an error using the yerr parameter. \n",
    "                                                                      # I defined the error as the standard deviation.  \n",
    "ax.set_xticks([1,2,3])  #I limited it to two ticks on the x axis \n",
    "ax.set_xticklabels(['Condition 1','Condition 2','Condition 3']) #I manually selected the x tick labels \n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_ylabel('Mean Response Time (sec)')\n",
    "#"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fda1d92c402c9d5e0550eab7f590eb1c0582e487619314e6aa12d68c281f0580"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}